{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Translation\n",
    "we will fine-tune a Marian model pretrained to translate from English to Korean (since a lot of Hugging Face employees speak both those languages) on the KDE4 dataset, which is a dataset of localized files for the KDE apps (KDE: KDE is an international free software community that develops free and open-source software). The model we will use has been pretrained on a large corpus of Korean and English texts taken from the Opus dataset, which actually contains the KDE4 dataset.\n",
    "\n",
    "This is the work on translation from english to korean using the pretrained model checkpoint by Jörg Tiedemann, professor of Department of Digital Hamanities\n",
    "\n",
    "![Jörg Tiedemann](https://researchportal.helsinki.fi/files-asset/56125518/Tiedemann.png?w=160&f=webp)\n",
    "\n",
    "#### MarianMT\n",
    "Models were originally trained by Jörg Tiedemann using the Marian C++ library, which supports fast training and translation.\n",
    "\n",
    "Since Marian models are smaller than many other translation models available in the library, they can be useful for fine-tuning experiments and integration tests.\n",
    "\n",
    "#### Multilingual Models\n",
    "\n",
    "- All model names use the following format: Helsinki-NLP/opus-mt-{src}-{tgt}:\n",
    "- If a model can output multiple languages, and you should specify a language code by prepending the desired output language to the src_text.\n",
    "- You can see a models’s supported language codes in its model card, under target constituents, like in opus-mt-en-roa.\n",
    "- Note that if a model is only multilingual on the source side, like Helsinki-NLP/opus-mt-roa-en, no language codes are required."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/gdrive',force_remount=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install accelerate -U\n",
    "# please restart after this installment"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install transformers datasets evaluate sentencepiece"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install huggingface_hub"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### OPUS\n",
    "OPUS is a growing collection of translated texts from the web. In the OPUS project we try to convert and align free online data, to add linguistic annotation, and to provide the community with a publicly available parallel corpus. OPUS is based on open source products and the corpus is also delivered as an open content package. We used several tools to compile the current collection. All pre-processing is done automatically. No manual corrections have been carried out.\n",
    "#### Sub-corpora\n",
    "kd4 datasets"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset kde4 (C:/Users/clee/.cache/huggingface/datasets/kde4/en-ko-lang1=en,lang2=ko/0.0.0/243129fb2398d5b0b4f7f6831ab27ad84774b7ce374cf10f60f6e1ff331648ac)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9f52521e9cfd4a8da9f188d2cbc3587e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "raw_ds = load_dataset(\"kde4\",lang1=\"en\",lang2=\"ko\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-27T08:02:18.612173200Z",
     "start_time": "2023-07-27T08:02:14.304380400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['id', 'translation'],\n        num_rows: 76708\n    })\n})"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_ds"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-27T08:02:23.221611200Z",
     "start_time": "2023-07-27T08:02:23.191691Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "{'id': ['0',\n  '1',\n  '2',\n  '3',\n  '4',\n  '5',\n  '6',\n  '7',\n  '8',\n  '9',\n  '10',\n  '11',\n  '12',\n  '13',\n  '14',\n  '15',\n  '16',\n  '17',\n  '18',\n  '19'],\n 'translation': [{'en': 'An Introduction to & kde;', 'ko': '& kde; 소개'},\n  {'en': 'The & kde; Team', 'ko': 'kde; 팀'},\n  {'en': 'ROLES_OF_TRANSLATORS',\n   'ko': 'Cedna sptcedna@ gmail. com KDE 4. 4 문서 번역 박 신조 peremen@ gmail. com 과거 문서 정리 및 번역'},\n  {'en': 'The & kde; Team', 'ko': 'kde; 팀'},\n  {'en': 'An introduction to the K Desktop Environment', 'ko': 'K 데스크톱 환경 소개'},\n  {'en': 'Quick Start Guide to & kde;', 'ko': '& kde; 빠른 시작 가이드'},\n  {'en': 'KDE', 'ko': 'KDE'},\n  {'en': 'quick start', 'ko': '빠른 시작'},\n  {'en': 'introduction', 'ko': '소개'},\n  {'en': 'Introduction', 'ko': '소개'},\n  {'en': 'This document is a brief introduction to the K Desktop Environment. It will familiarize you with some of the basic features of & kde;.',\n   'ko': '이 문서는 K 데스크톱 환경을 간단히 소개합니다. 이 문서를 읽으면 & kde; 의 기본적인 기능에 익숙해질 것입니다.'},\n  {'en': 'This guide is far from covering all aspects of the K Desktop or even most of them. It will only describe some of the most basic ways to accomplish a few of the most common tasks.',\n   'ko': '이 문서에서는 K 데스크톱의 모든 부분을 다루지는 않습니다. 이 문서는 일상적인 작업을 하는 데 필요한 기본적인 방법만 설명할 것입니다.'},\n  {'en': 'We assume that you are already familiar with at least one graphical user interface, for example CDE;, Geos, GEM, & NeXTSTEP;, & Mac;, OS/ 2 or & Microsoft; & Windows;. So we will not explain the usage of the mouse or the keyboard but concentrate on hopefully more interesting things.',\n   'ko': '이 문서에서는 여러분이 최소한 하나의 그래픽 사용자 환경에는 익숙하다고 생각합니다. 예를 들어, CDE;, Geos, GEM, & NeXTSTEP;, & Mac;, OS/ 2 또는 & Microsoft; & Windows; 등입니다. 마우스와 키보드 사용법과 같은 것보다는 좀 더 재미있는 것에 대해서 설명할 것입니다.'},\n  {'en': 'An Overview of & kde;', 'ko': '& kde; 개요'},\n  {'en': 'This section is for users who prefer to learn by exploring and want only a brief orientation to get started. Later sections provide a more thorough introduction to the environment, with helpful hints and shortcuts. If you are impatient to get started, skim this section, go play for a bit, then come back and peruse the other sections of this guide as needed.',\n   'ko': '이 장은 바로 시작하기 위해서 간단한 설명을 읽어 보고 싶은 사용자들을 위한 것입니다. 나중에 나오는 장들은 데스크톱 환경에 대한 더 깊은 소개를 할 것이며, 도움이 되는 팁과 단축키 등을 알려 줍니다. 바로 시작하고 싶으시다면, 이 장을 건너뛰고 다른 장으로 바로 가셔도 됩니다.'},\n  {'en': '& kde; provides a highly configurable desktop environment. This overview assumes that you are using the default environment.',\n   'ko': '& kde; 는 다양한 부분을 설정할 수 있는 데스크톱 환경입니다. 이 문서에서는 여러분이 기본적인 데스크톱 환경을 사용한다는 것을 가정합니다.'},\n  {'en': 'The & kde; Desktop', 'ko': '& kde; 데스크톱'},\n  {'en': 'A typical & kde; desktop consists of several parts:',\n   'ko': '전형적인 & kde; 데스크톱은 다음 부분으로 구성됩니다:'},\n  {'en': 'A panel at the bottom of the screen, used to start applications and switch between desktops. Among other things, it contains the & kmenu;, a large & kicon; which displays a menu of applications to start when clicked.',\n   'ko': '화면 아래에 있는 패널 은 프로그램을 시작하거나 데스크톱 사이를 전환하는 데 사용됩니다. 패널에는 커다란 & kicon; 인 & kmenu; 가 있습니다. 이것을 누르면 시작할 수 있는 프로그램 목록이 나타납니다.'},\n  {'en': 'A taskbar, by default embedded in the panel, used to switch between and manage currently running applications. Click on an application on the taskbar to switch to the application.',\n   'ko': '작업 표시줄 은 패널 안에 들어 있으며, 현재 실행 중인 프로그램을 관리하고 전환할 수 있도록 해 줍니다. 작업 표시줄에 있는 프로그램을 누르면 프로그램 사이를 전환할 수 있습니다.'}]}"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_ds[\"train\"][:20]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-27T08:02:24.693393300Z",
     "start_time": "2023-07-27T08:02:24.647517600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached split indices for dataset at C:\\Users\\clee\\.cache\\huggingface\\datasets\\kde4\\en-ko-lang1=en,lang2=ko\\0.0.0\\243129fb2398d5b0b4f7f6831ab27ad84774b7ce374cf10f60f6e1ff331648ac\\cache-7a2aba6b6520f180.arrow and C:\\Users\\clee\\.cache\\huggingface\\datasets\\kde4\\en-ko-lang1=en,lang2=ko\\0.0.0\\243129fb2398d5b0b4f7f6831ab27ad84774b7ce374cf10f60f6e1ff331648ac\\cache-3e75064839895ede.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['id', 'translation'],\n        num_rows: 69037\n    })\n    test: Dataset({\n        features: ['id', 'translation'],\n        num_rows: 7671\n    })\n})"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_datasets = raw_ds[\"train\"].train_test_split(train_size=0.9,seed=20)\n",
    "split_datasets"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-27T08:02:27.123215900Z",
     "start_time": "2023-07-27T08:02:27.064372600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "split_datasets[\"validation\"] = split_datasets.pop(\"test\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-27T08:02:29.281088200Z",
     "start_time": "2023-07-27T08:02:29.265130400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "{'en': 'Please add the output filename (%f) to the command line.',\n 'ko': '명령 라인에 출력될 파일 이름 (% f) 을( 를) 추가하십시오.'}"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_datasets[\"train\"][1][\"translation\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-27T08:02:30.281297200Z",
     "start_time": "2023-07-27T08:02:30.226443Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Change of pretrained model\n",
    "The model should be Helsinki-NLP/opus-mt-en-ko which is not working at the moment and should be replaced\n",
    "by circulus/kobart-trans-en-ko-v2 which is the only pretrained model currently available on internet.\n",
    "No description for the model is available."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "Downloading (…)okenizer_config.json:   0%|          | 0.00/304 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "90cbc83c8fe74bf4b5c4b0c246bb1d9f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\clee\\venv10\\lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\clee\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Downloading tokenizer.json:   0%|          | 0.00/1.05M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f0a696ad00ea44ca9ca36c3c3743ceb8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/123 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "46e6c16df59741fa93f9aa685f6a0f41"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "model_ckpt = \"circulus/kobart-trans-en-ko-v2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-27T08:02:38.909606900Z",
     "start_time": "2023-07-27T08:02:34.534706900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.45k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f814995209e14b93a3ed223a7769b82e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n",
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
     ]
    },
    {
     "data": {
      "text/plain": "Downloading pytorch_model.bin:   0%|          | 0.00/496M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cb0eaadcfb4649cfae392b52d026c748"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "[{'translation_text': '기본 확장된 실로'}]"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "translator = pipeline(\"translation\", model=model_ckpt)\n",
    "translator(\"Default to expanded threads\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-27T08:04:38.475734400Z",
     "start_time": "2023-07-27T08:02:44.007506500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your input_length: 32 is bigger than 0.9 * max_length: 20. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n"
     ]
    },
    {
     "data": {
      "text/plain": "[{'translation_text': '나는 번역을 위한 원어민 처리 작업을 하고 싶습니다'}]"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translator(\n",
    "    \"I want to work on natiral language processing for translation.\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-27T08:05:32.243093Z",
     "start_time": "2023-07-27T08:05:31.166263300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "[{'translation_text': 'OFX 수입자 플러그인을 사용하여 α1을 수입할 수 없음 · 이 파일은 올바른 형식이 아닙니다 ·'}]"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translator(\n",
    "    \"Unable to import %1 using the OFX importer plugin. This file is not the correct format.\",max_length=400\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-27T08:08:37.899447500Z",
     "start_time": "2023-07-27T08:08:36.608897600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "{'input_ids': [15073, 16203, 296, 17223, 1700, 18914, 299, 21235, 1700, 17884, 25088, 23124, 17254, 17761, 15265, 17941, 300, 14338, 236, 301, 240, 27141, 21235, 1700, 15190, 20461, 19465, 25674, 29144, 245], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [19899, 14560, 18288, 14175, 10314, 9910, 29504, 14897, 14338, 236, 17254, 240, 15309, 239, 15715, 240, 14927, 13586, 20108, 245]}"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_sentence = split_datasets[\"train\"][1][\"translation\"][\"en\"]\n",
    "ko_sentence = split_datasets[\"train\"][1][\"translation\"][\"ko\"]\n",
    "\n",
    "inputs = tokenizer(en_sentence, text_target=ko_sentence)\n",
    "inputs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-27T08:12:17.989840800Z",
     "start_time": "2023-07-27T08:12:17.975879600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁명령', '▁라', '인에', '▁출', '력', '될', '▁파일', '▁이름', '▁(', '%', '▁f', ')', '▁을', '(', '▁를', ')', '▁추가', '하', '십시오', '.']\n",
      "['▁명령', '▁라', '인에', '▁출', '력', '될', '▁파일', '▁이름', '▁(', '%', '▁f', ')', '▁을', '(', '▁를', ')', '▁추가', '하', '십시오', '.']\n"
     ]
    }
   ],
   "source": [
    "wrong_targets = tokenizer(ko_sentence)\n",
    "print(tokenizer.convert_ids_to_tokens(wrong_targets[\"input_ids\"]))\n",
    "print(tokenizer.convert_ids_to_tokens(inputs[\"labels\"]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-27T08:12:19.287514800Z",
     "start_time": "2023-07-27T08:12:19.254606200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "max_length = 128\n",
    "# Can this size of max-length be made larger ? Can the memory of GPU affected by this size?\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    inputs = [ex[\"en\"] for ex in examples[\"translation\"]]\n",
    "    targets = [ex[\"ko\"] for ex in examples[\"translation\"]]\n",
    "    model_inputs = tokenizer(\n",
    "        inputs, text_target=targets, max_length=max_length, truncation=True\n",
    "    )\n",
    "    return model_inputs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-27T08:14:12.964608600Z",
     "start_time": "2023-07-27T08:14:12.934690Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/69037 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "99758aac927d4332a5f166c79b12ed11"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/7671 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1e0dee2f8f5e47ac93d02f4d806f8bef"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_datasets = split_datasets.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    remove_columns=split_datasets[\"train\"].column_names,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-27T08:15:10.439312900Z",
     "start_time": "2023-07-27T08:15:04.676722800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_ckpt)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-27T08:16:03.693890600Z",
     "start_time": "2023-07-27T08:16:01.044893300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-27T08:16:19.415310100Z",
     "start_time": "2023-07-27T08:16:19.397358600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels', 'decoder_input_ids'])"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = data_collator([tokenized_datasets[\"train\"][i] for i in range(1, 3)])\n",
    "batch.keys()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-27T08:16:56.497623100Z",
     "start_time": "2023-07-27T08:16:56.477675900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[19899, 14560, 18288, 14175, 10314,  9910, 29504, 14897, 14338,   236,\n         17254,   240, 15309,   239, 15715,   240, 14927, 13586, 20108,   245],\n        [26755, 11973, 26052,   299, 23590, 15555,   315, 16203, 14338,   307,\n         24508,   316, 19650, 20280,  -100,  -100,  -100,  -100,  -100,  -100]])"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"labels\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-27T08:17:02.025842900Z",
     "start_time": "2023-07-27T08:17:02.002902500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[    1, 19899, 14560, 18288, 14175, 10314,  9910, 29504, 14897, 14338,\n           236, 17254,   240, 15309,   239, 15715,   240, 14927, 13586, 20108],\n        [    1, 26755, 11973, 26052,   299, 23590, 15555,   315, 16203, 14338,\n           307, 24508,   316, 19650, 20280,     3,     3,     3,     3,     3]])"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"decoder_input_ids\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-27T08:17:05.925124500Z",
     "start_time": "2023-07-27T08:17:05.890187Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19899, 14560, 18288, 14175, 10314, 9910, 29504, 14897, 14338, 236, 17254, 240, 15309, 239, 15715, 240, 14927, 13586, 20108, 245]\n",
      "[26755, 11973, 26052, 299, 23590, 15555, 315, 16203, 14338, 307, 24508, 316, 19650, 20280]\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 3):\n",
    "    print(tokenized_datasets[\"train\"][i][\"labels\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-27T08:17:22.626414500Z",
     "start_time": "2023-07-27T08:17:22.484793700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install sacrebleu"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"sacrebleu\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-27T08:18:02.863229100Z",
     "start_time": "2023-07-27T08:18:01.414373Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "{'score': 46.750469682990165,\n 'counts': [11, 6, 4, 3],\n 'totals': [12, 11, 10, 9],\n 'precisions': [91.66666666666667,\n  54.54545454545455,\n  40.0,\n  33.333333333333336],\n 'bp': 0.9200444146293233,\n 'sys_len': 12,\n 'ref_len': 13}"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = [\n",
    "    \"This plugin lets you translate web pages between several languages automatically.\"\n",
    "]\n",
    "references = [\n",
    "    [\n",
    "        \"This plugin allows you to automatically translate web pages between several languages.\"\n",
    "    ]\n",
    "]\n",
    "metric.compute(predictions=predictions, references=references)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-27T08:18:10.545464800Z",
     "start_time": "2023-07-27T08:18:10.500585Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "{'score': 1.683602693167689,\n 'counts': [1, 0, 0, 0],\n 'totals': [4, 3, 2, 1],\n 'precisions': [25.0, 16.666666666666668, 12.5, 12.5],\n 'bp': 0.10539922456186433,\n 'sys_len': 4,\n 'ref_len': 13}"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = [\"This This This This\"]\n",
    "references = [\n",
    "    [\n",
    "        \"This plugin allows you to automatically translate web pages between several languages.\"\n",
    "    ]\n",
    "]\n",
    "metric.compute(predictions=predictions, references=references)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-27T08:18:46.420767500Z",
     "start_time": "2023-07-27T08:18:46.380876200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    # In case the model returns more than the prediction logits\n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "\n",
    "    # Replace -100s in the labels as we can't decode them\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    # Some simple post-processing\n",
    "    decoded_preds = [pred.strip() for pred in decoded_preds]\n",
    "    decoded_labels = [[label.strip()] for label in decoded_labels]\n",
    "\n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    return {\"bleu\": result[\"score\"]}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-27T08:18:55.261027300Z",
     "start_time": "2023-07-27T08:18:55.240085400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "# fp16 seems to be crucial to reduce the memory size of GPU. Without this option, the job fails at colab.\n",
    "# The other metaparameters that affect the required size of GPU memory are\n",
    "#     batch_size for the train and evals.\n",
    "# Here, their values are set to 32 and 64, respectively.\n",
    "\n",
    "from transformers import Seq2SeqTrainingArguments\n",
    "\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    f\"marian-finetuned-kde4-en-to-ko\",\n",
    "    evaluation_strategy=\"no\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=64,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=3,\n",
    "    predict_with_generate=True,\n",
    "    fp16=True,\n",
    "    push_to_hub=True,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-27T08:19:02.795760200Z",
     "start_time": "2023-07-27T08:19:02.445212800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning https://huggingface.co/chunwoolee0/marian-finetuned-kde4-en-to-ko into local empty directory.\n"
     ]
    },
    {
     "data": {
      "text/plain": "Download file pytorch_model.bin:   0%|          | 17.4k/798M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "83a74a676457458bb8bfa13e7bb5c9ea"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Download file runs/Jul27_05-47-44_c3b97e2f7dd3/events.out.tfevents.1690438058.c3b97e2f7dd3.662.0: 100%|#######…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "35239124a67a4236aee3fb51ee38da5f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Download file target.spm:   2%|1         | 15.4k/796k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "59714258114f4a5995f96fbe83ba5cf3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Download file source.spm:   0%|          | 3.37k/771k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b779096dc6ee4f468b970f4b9b657043"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Download file runs/Jul27_05-47-44_c3b97e2f7dd3/events.out.tfevents.1690440358.c3b97e2f7dd3.662.1: 100%|#######…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ee07d0f4dc834a46ad1684307b925055"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Download file training_args.bin: 100%|##########| 4.06k/4.06k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8f7508228c8f433ab6fb75d8a926b4ef"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Clean file source.spm:   0%|          | 1.00k/771k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "826d3694377d4d9d8c1cfa38533d9207"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Clean file target.spm:   0%|          | 1.00k/796k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1bbcf4fef80741f1bc3521432bed0857"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Clean file runs/Jul27_05-47-44_c3b97e2f7dd3/events.out.tfevents.1690438058.c3b97e2f7dd3.662.0:  14%|#4        …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9b41d8841e374b299cd7cdc8e9b82395"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Clean file runs/Jul27_05-47-44_c3b97e2f7dd3/events.out.tfevents.1690440358.c3b97e2f7dd3.662.1: 100%|##########…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d3716f7bdfcc4b43a02cf0f0c678d1ee"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Clean file training_args.bin:  25%|##4       | 1.00k/4.06k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "45d85034c0944dca8323017bfe842376"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Clean file pytorch_model.bin:   0%|          | 1.00k/798M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d6b3acd75b3942d1a2a6014bbc7dbca5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import Seq2SeqTrainer\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-27T08:23:27.131333100Z",
     "start_time": "2023-07-27T08:19:09.740421500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trainer.evaluate(max_length=max_length)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trainer.push_to_hub(tags=\"translation\", commit_message=\"Training complete\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "translator = pipeline(\"translation\", model=\"chunwoolee0/circulus-kobart-en-to-ko\")\n",
    "translator(\"This course is produced by Hugging Face.\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "translator(\"This course is produced by Hugging Face.\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "translator(\"I ate the breakfast.\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
